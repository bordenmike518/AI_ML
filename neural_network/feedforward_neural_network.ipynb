{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer:\n",
    "    def __init__(self, count, prevCount, first=False):\n",
    "        self.count = count\n",
    "        self.prevCount = prevCount\n",
    "        self.randNormChoices = \n",
    "        np.random.shuffle(self.randNormChoices)\n",
    "        self.neurons = None\n",
    "        self.errors = None\n",
    "        if(not first):\n",
    "            self.synapses = np.random.choice(\n",
    "                                np.append(np.random.normal(-0.5, 0.1, \n",
    "                                    np.max([self.count, self.prevCount])),\n",
    "                                np.random.normal(0.5, 0.1, \n",
    "                                    np.max([self.count, self.prevCount]))), \n",
    "                                (self.count, self.prevCount)) \n",
    "        del self.randNormChoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = 0\n",
    "        self.network = list()\n",
    "\n",
    "    def initNetwork(self, networkStruct):\n",
    "        self.layers = len(networkStruct)\n",
    "        self.network.append(NeuronLayer(networkStruct[0], 0, True))\n",
    "        for i in range(self.layers-1):\n",
    "            self.network.append(NeuronLayer(networkStruct[i+1], networkStruct[i]))\n",
    "\n",
    "    def feedForward(self, data):\n",
    "        self.network[0].neurons = data.reshape(self.network[0].count, 1)\n",
    "        for i in range(self.layers-2):\n",
    "            self.network[i+1].neurons = self.tanh(np.dot(self.network[i+1].synapses, \n",
    "                                                         self.network[i].neurons))\n",
    "        self.network[-1].neurons = self.softmax(np.dot(self.network[-1].synapses, \n",
    "                                                       self.network[-2].neurons))\n",
    "\n",
    "    def backpropagation(self, target, learningRate):\n",
    "        self.network[-1].errors = target - self.network[-1].neurons\n",
    "        for i in reversed(range(1, self.layers)):\n",
    "            self.network[i].synapses += learningRate * np.dot(self.network[i].errors, \n",
    "                                                              self.network[i-1].neurons.T)\n",
    "            self.network[i-1].errors = np.dot(self.network[i].synapses.T, \n",
    "                                              self.network[i].errors)\n",
    "\n",
    "    def train(self, trainLabels, trainData, testLabels, testData, \n",
    "                    epochs, learningRate, withOutput=False):\n",
    "        for i in range(epochs):\n",
    "            print('\\t-- Epoch {}'.format(i+1))\n",
    "            for label, data in zip(trainLabels, trainData):\n",
    "                target = self.oneHotEncode(label-1)\n",
    "                self.feedForward(data)\n",
    "                self.backpropagation(target, learningRate)\n",
    "            if(withOutput):\n",
    "                accuracy = self.test(testLabels, testData)\n",
    "                print('Accuracy = {0:.2f}%'.format(accuracy*100))\n",
    "\n",
    "    def test(self, labels, testData):\n",
    "        correct = 0\n",
    "        for i, (label, data) in enumerate(zip(labels, testData)):\n",
    "            self.feedForward(data)\n",
    "            bestIndex = np.argmax(self.network[-1].neurons)\n",
    "            if (label == bestIndex+1):\n",
    "                correct += 1\n",
    "        return correct / len(labels)\n",
    "\n",
    "    def oneHotEncode(self, index):\n",
    "        vect = np.zeros((self.network[-1].count, 1))\n",
    "        vect[index] = 1\n",
    "        return vect\n",
    "\n",
    "    def sigmoid(self, A):\n",
    "        return 1 / (1 + np.exp(-A))\n",
    "\n",
    "    def tanh(self, A):\n",
    "        return np.tanh(A)\n",
    "\n",
    "    def ReLU(self, A):\n",
    "        return np.where(A > 0, A, 0)\n",
    "\n",
    "    def softmax(self, A):\n",
    "        e = np.exp(A - np.max(A))\n",
    "        return e / e.sum()\n",
    "        \n",
    "    def crossEntropy(self, y, X, epsilon=1e-12):\n",
    "        X = np.clip(X, epsilon, 1. - epsilon)\n",
    "        N = X.shape[0]\n",
    "        ce = -np.sum(y*np.log(X+1e-9))/N\n",
    "        return ce\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def standardize(self, A):\n",
    "        return (A - np.mean(A)) / np.std(A)\n",
    "\n",
    "    def normalize(self, A):\n",
    "        return (A - np.min(A)) / (np.max(A) - np.min(A))\n",
    "\n",
    "    def extractMNIST(self, fileName):\n",
    "        labels = []\n",
    "        fname = open(fileName, \"r\")\n",
    "        values = fname.readlines()[:20000]\n",
    "        fname.close()\n",
    "        for i, record in enumerate(values):\n",
    "            data = record.split(\",\")\n",
    "            values[i] = self.standardize(np.asfarray(data[1:]))\n",
    "            labels.append(int(data[0]))\n",
    "        return labels, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Network\n",
      "Opening Training Data\n",
      "Opening Testing Data\n",
      "Training:\n",
      "\t-- Epoch 1\n",
      "Accuracy = 68.96%\n",
      "\t-- Epoch 2\n",
      "Accuracy = 73.15%\n",
      "\t-- Epoch 3\n",
      "Accuracy = 74.51%\n",
      "\t-- Epoch 4\n",
      "Accuracy = 73.53%\n",
      "\t-- Epoch 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-903a6a22e129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m ann.train(MNIST_Train_Labels, MNIST_Train_Values, MNIST_Test_Labels, MNIST_Test_Values, \n\u001b[0;32m---> 22\u001b[0;31m           epochs, learningRate, displayOutput)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-2ce1a225975c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainLabels, trainData, testLabels, testData, epochs, learningRate, withOutput)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moneHotEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-2ce1a225975c>\u001b[0m in \u001b[0;36mfeedForward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             self.network[i+1].neurons = self.tanh(np.dot(self.network[i+1].synapses, \n\u001b[0;32m---> 16\u001b[0;31m                                                          self.network[i].neurons))\n\u001b[0m\u001b[1;32m     17\u001b[0m         self.network[i+2].neurons = self.softmax(np.dot(self.network[i+2].synapses, \n\u001b[1;32m     18\u001b[0m                                                          self.network[i+1].neurons))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of training sessions\n",
    "network = [784, 100, 100, 10]\n",
    "epochs = 5\n",
    "learningRate = 0.01\n",
    "displayOutput = True\n",
    "dl = DataLoader()\n",
    "\n",
    "# Create neural network\n",
    "print(\"Creating Network\")\n",
    "ann = NeuralNetwork()\n",
    "ann.initNetwork(network)\n",
    "\n",
    "# Open file to loop through\n",
    "print(\"Opening Training Data\")\n",
    "MNIST_Train_Labels, MNIST_Train_Values = dl.extractMNIST(\"MNIST/mnist_train.csv\")\n",
    "print(\"Opening Testing Data\")\n",
    "MNIST_Test_Labels, MNIST_Test_Values = dl.extractMNIST(\"MNIST/mnist_test.csv\")\n",
    "\n",
    "# Train\n",
    "print(\"Training:\")\n",
    "ann.train(MNIST_Train_Labels, MNIST_Train_Values, MNIST_Test_Labels, MNIST_Test_Values, \n",
    "          epochs, learningRate, displayOutput)\n",
    "\n",
    "# Test\n",
    "if (not displayOutput):\n",
    "    print(\"Testing:\")\n",
    "    accuracy = ann.test(MNIST_Test_Labels, MNIST_Test_Values)\n",
    "\n",
    "    # Print Accuracy\n",
    "    print(\"Accuracy = %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
