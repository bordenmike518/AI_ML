{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "np.random.seed(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer:\n",
    "    def __init__(self, prevCount, count, first=False):\n",
    "        self.prevCount = prevCount\n",
    "        self.count = count\n",
    "        self.neurons = None\n",
    "        self.errors = None\n",
    "        self.bias = np.ones((self.count, 1))\n",
    "        if(not first):\n",
    "            self.synapses = np.random.rand(self.count, self.prevCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = 0\n",
    "        self.network = list()\n",
    "\n",
    "    def initNetwork(self, networkStruct):\n",
    "        self.layers = len(networkStruct)\n",
    "        self.network.append(NeuronLayer(0, networkStruct[0], True))\n",
    "        for i in range(1, self.layers):\n",
    "            self.network.append(NeuronLayer(networkStruct[i-1], networkStruct[i]))\n",
    "\n",
    "    def feedForward(self, data):\n",
    "        self.network[0].neurons = data.reshape(self.network[0].count, 1)\n",
    "        for i in range(1, self.layers-1):\n",
    "            self.network[i].neurons = self.sigmoid(np.dot(self.network[i].synapses, \n",
    "                                                         self.network[i-1].neurons))\n",
    "        self.network[i+1].neurons = self.softmax(np.dot(self.network[i+1].synapses, \n",
    "                                                         self.network[i].neurons))\n",
    "        \n",
    "\n",
    "    def backpropagation(self, target, learningRate):\n",
    "        self.network[-1].errors = target - self.network[-1].neurons\n",
    "        for i in reversed(range(1, self.layers)):\n",
    "            self.network[i].synapses += learningRate * np.dot(\n",
    "                self.network[i].errors * self.sigmoid_derivative(self.network[i].neurons),\n",
    "                self.network[i-1].neurons.T\n",
    "            )\n",
    "            self.network[i-1].errors = np.dot(\n",
    "                self.network[i].synapses.T,\n",
    "                self.network[i].errors\n",
    "            )\n",
    "\n",
    "    def train(self, trainLabels, trainData, epochs=1, testLabels=[], \n",
    "                    testData=[], learningRate=None, withOutput=False):\n",
    "        for i in range(epochs):\n",
    "            print('\\t-- Epoch {}'.format(i+1))\n",
    "            for label, data in zip(trainLabels, trainData):\n",
    "                target = self.oneHotEncode(label-1)\n",
    "                self.feedForward(data)\n",
    "                self.backpropagation(target, learningRate)\n",
    "            if(withOutput):\n",
    "                accuracy = self.test(testLabels, testData)\n",
    "                print('Accuracy = {0:.2f}%'.format(accuracy*100))\n",
    "\n",
    "    def test(self, labels, testData):\n",
    "        correct = 0\n",
    "        for i, (label, data) in enumerate(zip(labels, testData)):\n",
    "            self.feedForward(data)\n",
    "            bestIndex = np.argmax(self.network[-1].neurons)\n",
    "            if (label == bestIndex+1):\n",
    "                correct += 1\n",
    "        return correct/len(labels)\n",
    "\n",
    "    def oneHotEncode(self, index):\n",
    "        vect = np.zeros((self.network[-1].count, 1))\n",
    "        vect[index][0] = 1\n",
    "        return vect\n",
    "    \n",
    "    def logLikelihood(self, y, yhat):\n",
    "        return np.where((y/2)-0.5+yhat > 0, -np.log(np.abs((y/2)-0.5+yhat)), 0)\n",
    "\n",
    "    def sigmoid(self, A):\n",
    "        return 1 / (1 + np.exp(-A))\n",
    "\n",
    "    def sigmoid_derivative(self, A):\n",
    "        return A * (1 - A)\n",
    "\n",
    "    def tanh(self, A):\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def tanh_derivative(self, A):\n",
    "        return 1 - np.power(np.tanh(A), 2)\n",
    "\n",
    "    def ReLU(self, A):\n",
    "        return np.where(A > 0, A, 0)\n",
    "\n",
    "    def softmax(self, A):\n",
    "        e = np.exp(A - np.max(A))\n",
    "        return e / e.sum()\n",
    "    \n",
    "    def entropy(p):\n",
    "        return -np.sum(p*np.log2(p))\n",
    "        \n",
    "    def crossEntropy(self, p, q):\n",
    "        '''\n",
    "        p = true probability distribution (expected)\n",
    "        q = predicted probability distribution (guessed)\n",
    "        '''\n",
    "        return -np.sum(np.where(q > 0, p*np.log2(q), 0))\n",
    "\n",
    "    def KLDivergence(self, p, q):\n",
    "        return self.crossEntropy(p,q) - self.entropy(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def standardize(self, A):\n",
    "        return (A - np.mean(A)) / np.std(A)\n",
    "\n",
    "    def normalize(self, A):\n",
    "        return (A - np.min(A)) / (np.max(A) - np.min(A))\n",
    "\n",
    "    def extractMNIST(self, fileName):\n",
    "        labels = []\n",
    "        fname = open(fileName, \"r\")\n",
    "        values = fname.readlines()#[:20000]\n",
    "        fname.close()\n",
    "        for i, record in enumerate(values):\n",
    "            data = record.split(\",\")\n",
    "            values[i] = self.standardize(np.asfarray(data[1:]))\n",
    "            labels.append(int(data[0]))\n",
    "        return labels, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Network\n",
      "Opening Training Data\n",
      "Opening Testing Data\n",
      "Training:\n",
      "\t-- Epoch 1\n",
      "Accuracy = 79.99%\n",
      "\t-- Epoch 2\n",
      "Accuracy = 82.16%\n",
      "\t-- Epoch 3\n",
      "Accuracy = 83.14%\n",
      "\t-- Epoch 4\n",
      "Accuracy = 83.75%\n",
      "\t-- Epoch 5\n",
      "Accuracy = 84.23%\n",
      "\t-- Epoch 6\n",
      "Accuracy = 84.61%\n",
      "\t-- Epoch 7\n",
      "Accuracy = 84.89%\n",
      "\t-- Epoch 8\n",
      "Accuracy = 85.09%\n",
      "\t-- Epoch 9\n",
      "Accuracy = 85.24%\n",
      "\t-- Epoch 10\n",
      "Accuracy = 85.35%\n"
     ]
    }
   ],
   "source": [
    "# Test input parameters\n",
    "network = [784, 150, 10]\n",
    "epochs = 10\n",
    "learningRate = 0.0019\n",
    "displayOutput = True\n",
    "dl = DataLoader()\n",
    "\n",
    "# Create neural network\n",
    "print(\"Creating Network\")\n",
    "ann = NeuralNetwork()\n",
    "ann.initNetwork(network)\n",
    "\n",
    "# Open file to loop through\n",
    "print(\"Opening Training Data\")\n",
    "MNIST_Train_Labels, MNIST_Train_Values = dl.extractMNIST(\"MNIST/mnist_train.csv\")\n",
    "print(\"Opening Testing Data\")\n",
    "MNIST_Test_Labels, MNIST_Test_Values = dl.extractMNIST(\"MNIST/mnist_test.csv\")\n",
    "\n",
    "# Train\n",
    "print(\"Training:\")\n",
    "ann.train(MNIST_Train_Labels, MNIST_Train_Values, epochs,\n",
    "          MNIST_Test_Labels, MNIST_Test_Values, learningRate, displayOutput)\n",
    "\n",
    "# Test\n",
    "if (not displayOutput):\n",
    "    print(\"Testing:\")\n",
    "    accuracy = ann.test(MNIST_Test_Labels, MNIST_Test_Values)\n",
    "\n",
    "    # Print Accuracy\n",
    "    print(\"Accuracy = %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
